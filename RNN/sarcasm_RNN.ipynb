{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                        article_link  \n",
       "0  https://www.theonion.com/thirtysomething-scien...  \n",
       "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3  https://local.theonion.com/inclement-weather-p...  \n",
       "4  https://www.theonion.com/mother-comes-pretty-c...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(r\"C:\\Users\\Gokul\\Downloads\\sarcasm_kaggle\\Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_drop(column_name, data):\n",
    "    data1 = data.drop([column_name], axis = 1)\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28619, 3)\n",
      "(28617, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline\n",
       "0             1  thirtysomething scientists unveil doomsday clo...\n",
       "1             0  dem rep. totally nails why congress is falling...\n",
       "2             0  eat your veggies: 9 deliciously different recipes\n",
       "3             1  inclement weather prevents liar from getting t...\n",
       "4             1  mother comes pretty close to using word 'strea..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_drop('article_link', df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "y_data = df.is_sarcastic\n",
    "x_data = data_drop('is_sarcastic', df)\n",
    "print(x_data.size == y_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thirtysomething scientists unveil doomsday clock of hair loss', 'dem rep totally nails why congress is falling short on gender racial equality', 'eat your veggies 9 deliciously different recipes', 'inclement weather prevents liar from getting to work']\n",
      "['thirtysomething', 'scientists', 'unveil', 'doomsday', 'clock', 'of', 'hair', 'loss', 'dem', 'rep', 'totally', 'nails', 'why', 'congress', 'is', 'falling', 'short', 'on', 'gender', 'racial']\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "x_list = x_data['headline'].tolist()\n",
    "x_list = [x.lower() for x in x_list]\n",
    "def remove_punc(string):\n",
    "    for i in string:\n",
    "        if i in punctuation:\n",
    "            string = string.replace(i, \"\")\n",
    "    return string\n",
    "lines_split = [remove_punc(c) for c in x_list]\n",
    "print(lines_split[:4])\n",
    "# splitting using \\n\n",
    "words = [word for line in lines_split for word in line.split()]\n",
    "print(words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15526, 336, 3106, 6323, 2320, 2, 671, 1138], [7344, 1731, 732, 3107, 46, 226, 10, 1886, 1066, 7, 1659, 2102, 1732], [892, 34, 11206, 615, 15527, 606, 1447], [11207, 1596, 6324, 4497, 14, 138, 1, 143]]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(words)\n",
    "#print(counts)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "#print(vocab)\n",
    "vocab2int = {word:i for i, word in enumerate(vocab, 1)}\n",
    "#print(vocab2int)\n",
    "lines_ints= []\n",
    "for line in lines_split:\n",
    "    lines_ints.append([vocab2int[word] for word in line.split()])\n",
    "print(lines_ints[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words:  29667\n",
      "Tokenized review: \n",
      " [[15526, 336, 3106, 6323, 2320, 2, 671, 1138]]\n"
     ]
    }
   ],
   "source": [
    "# stats about vocabulary\n",
    "print('Unique words: ', len((vocab2int)))\n",
    "\n",
    "# print tokens in first review\n",
    "print('Tokenized review: \\n', lines_ints[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 1 1] (28617,)\n"
     ]
    }
   ],
   "source": [
    "encoded_labels = y_data.to_numpy()\n",
    "print(encoded_labels, encoded_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length lines: 0\n",
      "Maximum sarcasm line length: 151\n",
      "Counter({10: 3643, 9: 3433, 11: 3392, 8: 2935, 12: 2841, 7: 2407, 13: 2079, 6: 1777, 14: 1481, 5: 1170, 15: 952, 4: 594, 16: 579, 17: 379, 3: 307, 18: 225, 19: 142, 2: 119, 20: 63, 21: 45, 22: 23, 23: 13, 24: 3, 27: 3, 29: 2, 25: 2, 28: 2, 151: 1, 31: 1, 26: 1, 38: 1, 39: 1, 30: 1})\n"
     ]
    }
   ],
   "source": [
    "lines_lengths = Counter([len(x) for x in lines_ints])\n",
    "print(\"Zero-length lines: {}\".format(lines_lengths[0]))\n",
    "print(\"Maximum sarcasm line length: {}\".format(max(lines_lengths)))\n",
    "print(lines_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pad_features(lines_ints, seq_length):\n",
    "    features = np.zeros((len(lines_ints), seq_length), dtype=int)\n",
    "    for i, row in enumerate(lines_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "[[   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ... 7344 1731  732]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...    0    0  106]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 35\n",
    "features = pad_features(lines_ints, seq_length=seq_length)\n",
    "\n",
    "## test statements\n",
    "print(len(features)==len(lines_ints)) #Your features should have as many rows as reviews.\n",
    "print(len(features[0])==seq_length) #Each feature row should contain seq_length values.\n",
    "\n",
    "# print first 10 values of the first 30 batches\n",
    "print(features[:-30,:-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: \t\t(22893, 35) \n",
      "Validation set: \t(2862, 35) \n",
      "Test set: \t\t(2862, 35)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "half_idx = int(len(remaining_x)*0.5)\n",
    "valid_x, test_x = remaining_x[:half_idx], remaining_x[half_idx:]\n",
    "valid_y, test_y = remaining_y[:half_idx], remaining_y[half_idx:]\n",
    "\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape),\n",
    "      \"\\nValidation set: \\t{}\".format(valid_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating Tensor Datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x),torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_x),torch.from_numpy(valid_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x),torch.from_numpy(test_y))\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 35])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,  ...,     4,  1972,  6715],\n",
      "        [    0,     0,     0,  ...,  1154,   139,  1419],\n",
      "        [    0,     0,     0,  ...,   143,     5,  3540],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,    49,  1932,    17],\n",
      "        [    0,     0,     0,  ...,   859,  1987, 23478],\n",
      "        [    0,     0,     0,  ...,  2883,    34,   494]], dtype=torch.int32)\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "example = iter(train_loader)\n",
    "sample_x, sample_y = example.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embed_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(RNN, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Embedding and LSTM\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        # Dropout and FC after reshaping\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        sig_out = self.sig(out)\n",
    "        # Reshape to batch size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "\n",
    "        return sig_out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(29668, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "vocab_size = len(vocab2int)+1\n",
    "output_size = 1\n",
    "embed_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "epochs = 1\n",
    "lr = 0.001\n",
    "\n",
    "model = RNN(vocab_size, output_size, embed_dim, hidden_dim, n_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [07:02<00:00, 422.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Step: 10... Loss: 0.683962... Valid_loss: 0.671224...\n",
      "Epoch: 1/1... Step: 20... Loss: 0.598524... Valid_loss: 0.580768...\n",
      "Epoch: 1/1... Step: 30... Loss: 0.547371... Valid_loss: 0.560788...\n",
      "Epoch: 1/1... Step: 40... Loss: 0.473554... Valid_loss: 0.539025...\n",
      "Epoch: 1/1... Step: 50... Loss: 0.438349... Valid_loss: 0.526397...\n",
      "Epoch: 1/1... Step: 60... Loss: 0.588752... Valid_loss: 0.522343...\n",
      "Epoch: 1/1... Step: 70... Loss: 0.436827... Valid_loss: 0.510954...\n",
      "Epoch: 1/1... Step: 80... Loss: 0.443609... Valid_loss: 0.494042...\n",
      "Epoch: 1/1... Step: 90... Loss: 0.329247... Valid_loss: 0.492629...\n",
      "Epoch: 1/1... Step: 100... Loss: 0.622796... Valid_loss: 0.471140...\n",
      "Epoch: 1/1... Step: 110... Loss: 0.374756... Valid_loss: 0.460190...\n",
      "Epoch: 1/1... Step: 120... Loss: 0.418353... Valid_loss: 0.464494...\n",
      "Epoch: 1/1... Step: 130... Loss: 0.447154... Valid_loss: 0.456816...\n",
      "Epoch: 1/1... Step: 140... Loss: 0.458779... Valid_loss: 0.448546...\n",
      "Epoch: 1/1... Step: 150... Loss: 0.449444... Valid_loss: 0.471403...\n",
      "Epoch: 1/1... Step: 160... Loss: 0.424523... Valid_loss: 0.447794...\n",
      "Epoch: 1/1... Step: 170... Loss: 0.554983... Valid_loss: 0.444687...\n",
      "Epoch: 1/1... Step: 180... Loss: 0.498026... Valid_loss: 0.427843...\n",
      "Epoch: 1/1... Step: 190... Loss: 0.520537... Valid_loss: 0.436066...\n",
      "Epoch: 1/1... Step: 200... Loss: 0.488463... Valid_loss: 0.422259...\n",
      "Epoch: 1/1... Step: 210... Loss: 0.422782... Valid_loss: 0.419037...\n",
      "Epoch: 1/1... Step: 220... Loss: 0.365236... Valid_loss: 0.421876...\n",
      "Epoch: 1/1... Step: 230... Loss: 0.390051... Valid_loss: 0.411617...\n",
      "Epoch: 1/1... Step: 240... Loss: 0.399600... Valid_loss: 0.428098...\n",
      "Epoch: 1/1... Step: 250... Loss: 0.454589... Valid_loss: 0.411990...\n",
      "Epoch: 1/1... Step: 260... Loss: 0.337448... Valid_loss: 0.420114...\n",
      "Epoch: 1/1... Step: 270... Loss: 0.460902... Valid_loss: 0.410179...\n",
      "Epoch: 1/1... Step: 280... Loss: 0.402022... Valid_loss: 0.402335...\n",
      "Epoch: 1/1... Step: 290... Loss: 0.335750... Valid_loss: 0.428625...\n",
      "Epoch: 1/1... Step: 300... Loss: 0.383826... Valid_loss: 0.407900...\n",
      "Epoch: 1/1... Step: 310... Loss: 0.418864... Valid_loss: 0.397394...\n",
      "Epoch: 1/1... Step: 320... Loss: 0.489733... Valid_loss: 0.411621...\n",
      "Epoch: 1/1... Step: 330... Loss: 0.456026... Valid_loss: 0.386625...\n",
      "Epoch: 1/1... Step: 340... Loss: 0.371156... Valid_loss: 0.388424...\n",
      "Epoch: 1/1... Step: 350... Loss: 0.370123... Valid_loss: 0.379205...\n",
      "Epoch: 1/1... Step: 360... Loss: 0.285848... Valid_loss: 0.376765...\n",
      "Epoch: 1/1... Step: 370... Loss: 0.330238... Valid_loss: 0.368153...\n",
      "Epoch: 1/1... Step: 380... Loss: 0.434276... Valid_loss: 0.370826...\n",
      "Epoch: 1/1... Step: 390... Loss: 0.412494... Valid_loss: 0.365035...\n",
      "Epoch: 1/1... Step: 400... Loss: 0.404750... Valid_loss: 0.362967...\n",
      "Epoch: 1/1... Step: 410... Loss: 0.415301... Valid_loss: 0.370296...\n",
      "Epoch: 1/1... Step: 420... Loss: 0.315214... Valid_loss: 0.368378...\n",
      "Epoch: 1/1... Step: 430... Loss: 0.449239... Valid_loss: 0.372443...\n",
      "Epoch: 1/1... Step: 440... Loss: 0.377302... Valid_loss: 0.380034...\n",
      "Epoch: 1/1... Step: 450... Loss: 0.354180... Valid_loss: 0.361344...\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "print_every = 10\n",
    "clip = 5\n",
    "\n",
    "model.train()\n",
    "# Training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    h = model.init_hidden(batch_size)\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        output, h = model(inputs, h)\n",
    "        loss = loss_func(output.squeeze(), labels.float())\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter%print_every == 0:\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                output, val_h = model(inputs, val_h)\n",
    "                val_loss = loss_func(output.squeeze(), labels.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            model.train()\n",
    "            print('Epoch: {}/{}...'.format(epoch+1, epochs),\n",
    "                  'Step: {}...'.format(counter),\n",
    "                  'Loss: {:.6f}...'.format(loss.item()),\n",
    "                  'Valid_loss: {:.6f}...'.format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.360\n",
      "Test accuracy: 0.838\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "\n",
    "h = model.init_hidden(batch_size)\n",
    "model.eval()\n",
    "for inputs, labels in test_loader:\n",
    "    h = tuple([each.data for each in h])\n",
    "    output, h = model(inputs, h)\n",
    "    test_loss = loss_func(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "\n",
    "    # converting output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze()) # round to nearest integer\n",
    "\n",
    "    # compare pred with true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "def tokenize_line(test_line):\n",
    "    test_line = test_line.lower()\n",
    "    test_text = ''.join([c for c in test_line if c not in punctuation])\n",
    "    test_words = test_text.split()\n",
    "\n",
    "    test_ints = []\n",
    "    test_ints.append([vocab2int[word] for word in test_words])\n",
    "\n",
    "    return test_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, test_line, sequence_length = 35):\n",
    "    model.eval()\n",
    "    test_ints = tokenize_line(test_line)\n",
    "    seq_length = sequence_length\n",
    "    features = pad_features(test_ints, seq_length)\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "\n",
    "    batch_size = feature_tensor.size(0)\n",
    "    h = model.init_hidden(batch_size)\n",
    "    output, h = model(feature_tensor, h)\n",
    "    pred = torch.round(output.squeeze())\n",
    "\n",
    "    # printing output value, before rounding\n",
    "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
    "    # print response\n",
    "    if(pred.item()==1):\n",
    "        print(\"Sorry, you wouldn't get it!\")\n",
    "    else:\n",
    "        print(\"Just news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.875984\n",
      "Sorry, you wouldn't get it!\n"
     ]
    }
   ],
   "source": [
    "# negative test review\n",
    "test_line = \"boehner just wants wife to listen, not come up with alternative debt-reduction ideas\"\n",
    "# call function\n",
    "seq_length = 35 # good to use the length that was trained on\n",
    "predict(model, test_line, seq_length)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
